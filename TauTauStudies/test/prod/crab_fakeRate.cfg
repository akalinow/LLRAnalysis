[CRAB]

jobtype = cmssw
scheduler = glite
use_server = 1
#server_name=bari

[CMSSW]

datasetpath=
total_number_of_events=
events_per_job =

pset=/home/llr/cms/lbianchini/CMSSW_4_1_6/src/LLRAnalysis/TauTauStudies/test/patTuple_PAT_eToTauFakeRate_cfg.py

#lumi_mask = goodrunlist_json.txt
#total_number_of_lumis= -1
#lumis_per_job = 35
#total_number_of_events= 100
#events_per_job = 100

output_file = treeEtoTauTnP.root
##

[USER]

return_data = 0

#outputdir= /full/path/yourOutDir

copy_data = 1

storage_element = T2_FR_GRIF_LLR
### in the case of publication this directory is not considered
user_remote_dir = tauEffSpring11/


#publish_data=1
#publish_data_name = lb-Commissioning10-PfReReco_132440-134987
#dbs_url_for_publication = https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_01_writer/servlet/DBSServlet

#additional_input_files = /home/llr/cms/lbianchini/CMSSW_4_1_3_TauTau/src/LLRAnalysis/TauTauStudies/test/Jec10V3.db

#if server
thresholdLevel = 90
eMail = Your.EMail@cern.ch

[GRID]
#
## RB/WMS management:
rb = CERN

##  Black and White Lists management:
## By Storage
#se_black_list = T0,T1,T2_AT_Vienna,T2_FR_GRIF_IRFU,T2_US_UCSD,T2_HU_Budapest
se_black_list = T0,T1,T2_US_MIT
#,T2_US_MIT,T2_RU_SINP
#se_white_list = T2_IT_Legnaro

## By ComputingElement
#ce_black_list =
#ce_white_list =

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))


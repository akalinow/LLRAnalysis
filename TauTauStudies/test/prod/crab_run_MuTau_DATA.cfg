[CRAB]

jobtype = cmssw
scheduler = glite
use_server = 0
#server_name=bari
#scheduler = pbs

[CMSSW]

datasetpath=
total_number_of_events= 
events_per_job = 

pset=../runMuTauStreamAnalyzerFullAnalysis_Recoil_DATA_cfg.py

#lumi_mask = goodrunlist_json.txt
#total_number_of_lumis= -1
#lumis_per_job = 35
#total_number_of_events= 100
#events_per_job = 100

output_file = treeMuTauStream.root
##

[USER]

return_data = 0

#outputdir= /full/path/yourOutDir

copy_data = 1

storage_element = T2_FR_GRIF_LLR
### in the case of publication this directory is not considered
user_remote_dir = 


publish_data=0

#if server
thresholdLevel = 90
eMail = Aruna.Nayak@cern.ch

#[GRID]
#rb = CERN
#se_black_list = T0,T1,T2_US_MIT
#se_white_list = T2_FR_GRIF_LLR
#ce_black_list =
#ce_white_list =

[PBS]
queue = cms
#wnbase = /data_CMS/cms/lbianchini
wnbase = /var/spool/pbs/tmpdir

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

